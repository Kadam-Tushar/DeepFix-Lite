{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASEML_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP1XRi8suIlB",
        "outputId": "c3eb96c5-0ec6-496f-81e1-18400da15a0b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fci3CSgrPLY"
      },
      "source": [
        "import os\n",
        "use_tpu = True #@param {type:\"boolean\"}\n",
        "\n",
        "if use_tpu:\n",
        "    assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "else:\n",
        "  TF_MASTER=''"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57V3laOAvEK2",
        "outputId": "a023cf2a-d0aa-40f4-fd28-8db507678cde"
      },
      "source": [
        "!ls /content/drive/MyDrive/ASEML_dataset/\n",
        "!cp drive/MyDrive/ASEML_dataset/tokenization.py ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenization.py  tokenize_dataset.py  train.csv  valid.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhA6ZKZHxRX-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import ast \n",
        "import tokenization\n",
        "from vocabulary import Vocabulary"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNYYwAGDxVvG"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/ASEML_dataset/train.csv')\n",
        "test  = pd.read_csv('/content/drive/MyDrive/ASEML_dataset/valid.csv')\n",
        "\n",
        "\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsiIbikxw2Ai"
      },
      "source": [
        "#parameters\n",
        "sen_len  = 22\n",
        "vocab_size = 250 \n",
        "# TPU address\n",
        "tpu_address = TF_MASTER\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_sDOE-gyXkmx",
        "outputId": "09f4085e-d14b-492d-f2a8-34af34ed4626"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "dist={}\n",
        "\n",
        "train_orig = pd.read_csv('/content/drive/MyDrive/ASEML_dataset/train.csv')\n",
        "tokenizer = tokenization.C_Tokenizer()\n",
        "for index in train_orig.index:\n",
        "  tar_line = ast.literal_eval(train_orig['targetLineTokens'][index])\n",
        "  line = ' '.join(tar_line)\n",
        "  toks,types = tokenizer.tokenize(line)\n",
        "  if len(toks) in dist :\n",
        "    dist[len(toks)] +=1\n",
        "  else:\n",
        "    dist[len(toks)] = 1\n",
        "plt.scatter(dist.keys(),dist.values())\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBHMNUk8zUa2"
      },
      "source": [
        "def pre_process(data):\n",
        "  tokenizer = tokenization.C_Tokenizer()\n",
        "  data['src_id_var'] = \"\"\n",
        "  data['src_var_id'] = \"\"\n",
        "  data['src_lc_s'] = \"\"\n",
        "  data['src_lc_c']= \"\"\n",
        "  data['src_lc_n']= \"\"\n",
        "  data['src_lc_comm']= \"\"\n",
        "  if 'targetLineTokens' in data.columns:\n",
        "    data['tar_id_var'] = \"\"\n",
        "    data['tar_var_id'] = \"\"\n",
        "    data['tar_lc_s'] = \"\"\n",
        "    data['tar_lc_c']= \"\"\n",
        "    data['tar_lc_n']= \"\"\n",
        "    data['tar_lc_comm']= \"\"\n",
        "\n",
        "\n",
        "  for index in data.index:\n",
        "    src_line = ast.literal_eval(data['sourceLineTokens'][index])\n",
        "    line = ' '.join(src_line)\n",
        "    toks,types = tokenizer.tokenize(line)\n",
        "    num_var = list(set([toks[i] for i in range(len(toks)) if types[i]=='name']))\n",
        "    var_num = {num_var[i]:i for i in range(len(num_var))}\n",
        "    data['src_id_var'][index] = num_var\n",
        "    data['src_var_id'][index] = var_num\n",
        "    s_list=[]\n",
        "    c_list=[]\n",
        "    n_list=[]\n",
        "    com_list=[]\n",
        "    chk = var_num.keys();\n",
        "\n",
        "    for i,s in enumerate(toks):\n",
        "      if s in chk:\n",
        "        toks[i]='v'+str(var_num[s])\n",
        "      if types[i] == 'string':\n",
        "        s_list.append(toks[i])\n",
        "        toks[i]='lc_s'\n",
        "      if types[i] == 'char':\n",
        "        c_list.append(toks[i])\n",
        "        toks[i]='lc_c'\n",
        "      if types[i] == 'number':\n",
        "        n_list.append(toks[i])\n",
        "        toks[i]='lc_n'\n",
        "      if types[i] == 'comment':\n",
        "        com_list.append(toks[i])\n",
        "        toks[i] = 'lc_comm'\n",
        "    \n",
        "    normalised= ['SOS']\n",
        "    normalised.extend([toks[x] for x in range(min(sen_len-2,len(toks)))])\n",
        "    normalised.extend(['PAD' for x in range(sen_len -1 - len(normalised))])\n",
        "    normalised.append('EOS')\n",
        "     \n",
        "    data['sourceLineTokens'][index] = normalised\n",
        "    data['src_lc_s'][index] = s_list\n",
        "    data['src_lc_c'][index]= c_list\n",
        "    data['src_lc_n'][index]= n_list\n",
        "    data['src_lc_comm'][index]= com_list\n",
        "      \n",
        "    \n",
        "    if 'targetLineTokens' in data.columns:\n",
        "      tar_line = ast.literal_eval(data['targetLineTokens'][index])\n",
        "      line = ' '.join(tar_line)\n",
        "      toks,types = tokenizer.tokenize(line)\n",
        "      \n",
        "      num_var = list(set([toks[i] for i in range(len(toks)) if types[i]=='name']))\n",
        "      var_num = {num_var[i]:i for i in range(len(num_var))}\n",
        "      data['tar_id_var'][index] = num_var\n",
        "      data['tar_var_id'][index] = var_num\n",
        "      s_list=[]\n",
        "      c_list=[]\n",
        "      n_list=[]\n",
        "      com_list=[]\n",
        "      chk = var_num.keys();\n",
        "      for i,s in enumerate(toks):\n",
        "        if s in chk:\n",
        "          toks[i]='v'+str(var_num[s])\n",
        "        if types[i] == 'string':\n",
        "          s_list.append(toks[i])\n",
        "          toks[i]='lc_s'\n",
        "        if types[i] == 'char':\n",
        "          c_list.append(toks[i])\n",
        "          toks[i]='lc_c'\n",
        "        if types[i] == 'number':\n",
        "          n_list.append(toks[i])\n",
        "          toks[i]='lc_n'\n",
        "        if types[i] == 'comment':\n",
        "          com_list.append(toks[i])\n",
        "          toks[i] = 'lc_comm'\n",
        "      \n",
        "      \n",
        "      \n",
        "      normalised= ['SOS']\n",
        "      normalised.extend([toks[x] for x in range(min(sen_len-2,len(toks)))])\n",
        "      normalised.extend(['PAD' for x in range(sen_len -1 - len(normalised))])\n",
        "      normalised.append('EOS')\n",
        "     \n",
        "      data['targetLineTokens'][index] = normalised\n",
        "      data['tar_lc_s'][index] = s_list\n",
        "      data['tar_lc_c'][index]= c_list\n",
        "      data['tar_lc_n'][index]= n_list\n",
        "      data['tar_lc_comm'][index]= com_list\n",
        "    \n",
        "     \n",
        "      \n"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XQXlWv7_NyL",
        "outputId": "16886d50-a057-4fea-e99a-3bb15fbc59bf"
      },
      "source": [
        "pre_process(train)\n",
        "pre_process(test)\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:68: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abAEHmgwx_P3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94fefb57-fdf6-4baf-a60b-7fd037cff5a8"
      },
      "source": [
        "encoder_vocab = Vocabulary('encoder_vocab')\n",
        "decoder_vocab = Vocabulary('decoder_vocab')\n",
        "for line in train['sourceLineTokens']:\n",
        "  encoder_vocab.add_sentence(line)\n",
        "\n",
        "for line in train['targetLineTokens']:\n",
        "  decoder_vocab.add_sentence(line)\n",
        "\n",
        "print('Encoder vocab word count : ',encoder_vocab.num_words)\n",
        "print('Encoder vocab longest sentence ',encoder_vocab.longest_sentence)\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(train),encoder_vocab.longest_sentence, encoder_vocab.num_words), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(train), encoder_vocab.longest_sentence, encoder_vocab.num_words), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(train), encoder_vocab.longest_sentence, encoder_vocab.num_words), dtype=\"float32\"\n",
        ")\n",
        "for i, (input_text, target_text) in enumerate(zip(train['sourceLineTokens'],train['targetLineTokens'])):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, encoder_vocab.word2index[char]] = 1.0\n",
        "    \n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        if char in encoder_vocab.word2index:\n",
        "          decoder_input_data[i, t, encoder_vocab.word2index[char]] = 1.0\n",
        "        else:\n",
        "          decoder_input_data[i, t, encoder_vocab.word2index['OOV_Token']] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            if char in encoder_vocab.word2index:\n",
        "              decoder_target_data[i, t-1, encoder_vocab.word2index[char]] = 1.0\n",
        "            else:\n",
        "              decoder_target_data[i, t-1, encoder_vocab.word2index['OOV_Token']] = 1.0\n",
        "            "
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder vocab word count :  422\n",
            "Encoder vocab longest sentence  22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LaflxufsUD2",
        "outputId": "1dc4aad3-d242-4d80-e8b2-1d8b925e197b"
      },
      "source": [
        "import tensorflow as tf \n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TF_MASTER)\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.100.214.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.100.214.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.100.214.18:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.100.214.18:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyxuXgn7BU80"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "batch_size = 32  # Batch size for training.\n",
        "epochs = 22  # Number of epochs to train for.\n",
        "latent_dim_encoder = 160\n",
        "latent_dim_decoder = 160"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4icG2apa_VmW"
      },
      "source": [
        "num_encoder_tokens = encoder_vocab.num_words\n",
        "num_decoder_tokens = encoder_vocab.num_words\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim_encoder, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim_decoder, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knWB2ygx_bkZ",
        "outputId": "d5b6cb7c-4e5d-4cd5-8bb1-f43a20b3d8c8"
      },
      "source": [
        "#Train model \n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "# Save model\n",
        "model.save(\"third.h5\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/22\n",
            "367/367 [==============================] - 32s 78ms/step - loss: 2.0591 - accuracy: 0.5332 - val_loss: 1.2655 - val_accuracy: 0.6272\n",
            "Epoch 2/22\n",
            "367/367 [==============================] - 24s 64ms/step - loss: 1.0847 - accuracy: 0.6632 - val_loss: 0.8915 - val_accuracy: 0.6895\n",
            "Epoch 3/22\n",
            "367/367 [==============================] - 23s 63ms/step - loss: 0.7612 - accuracy: 0.7344 - val_loss: 0.6579 - val_accuracy: 0.7709\n",
            "Epoch 4/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.6312 - accuracy: 0.7704 - val_loss: 0.6193 - val_accuracy: 0.7801\n",
            "Epoch 5/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.5580 - accuracy: 0.7904 - val_loss: 0.5563 - val_accuracy: 0.7926\n",
            "Epoch 6/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.5202 - accuracy: 0.8042 - val_loss: 0.4854 - val_accuracy: 0.8152\n",
            "Epoch 7/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.4710 - accuracy: 0.8230 - val_loss: 0.4826 - val_accuracy: 0.8144\n",
            "Epoch 8/22\n",
            "367/367 [==============================] - 24s 64ms/step - loss: 0.4277 - accuracy: 0.8349 - val_loss: 0.4911 - val_accuracy: 0.8568\n",
            "Epoch 9/22\n",
            "367/367 [==============================] - 23s 63ms/step - loss: 0.4053 - accuracy: 0.8445 - val_loss: 0.4586 - val_accuracy: 0.8245\n",
            "Epoch 10/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.3896 - accuracy: 0.8536 - val_loss: 0.4111 - val_accuracy: 0.8723\n",
            "Epoch 11/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.3616 - accuracy: 0.8616 - val_loss: 0.4219 - val_accuracy: 0.8344\n",
            "Epoch 12/22\n",
            "367/367 [==============================] - 23s 61ms/step - loss: 0.3448 - accuracy: 0.8576 - val_loss: 0.3720 - val_accuracy: 0.8488\n",
            "Epoch 13/22\n",
            "367/367 [==============================] - 23s 63ms/step - loss: 0.3337 - accuracy: 0.8708 - val_loss: 0.3907 - val_accuracy: 0.8880\n",
            "Epoch 14/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.3072 - accuracy: 0.8811 - val_loss: 0.4084 - val_accuracy: 0.8842\n",
            "Epoch 15/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.2994 - accuracy: 0.8860 - val_loss: 0.4815 - val_accuracy: 0.8181\n",
            "Epoch 16/22\n",
            "367/367 [==============================] - 23s 63ms/step - loss: 0.2913 - accuracy: 0.8993 - val_loss: 0.3219 - val_accuracy: 0.9097\n",
            "Epoch 17/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.2739 - accuracy: 0.9140 - val_loss: 0.3721 - val_accuracy: 0.8963\n",
            "Epoch 18/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.2673 - accuracy: 0.9178 - val_loss: 0.3356 - val_accuracy: 0.9048\n",
            "Epoch 19/22\n",
            "367/367 [==============================] - 22s 61ms/step - loss: 0.2540 - accuracy: 0.9215 - val_loss: 0.3423 - val_accuracy: 0.9046\n",
            "Epoch 20/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.2483 - accuracy: 0.9166 - val_loss: 0.3481 - val_accuracy: 0.9049\n",
            "Epoch 21/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.2430 - accuracy: 0.9132 - val_loss: 0.3547 - val_accuracy: 0.8545\n",
            "Epoch 22/22\n",
            "367/367 [==============================] - 23s 62ms/step - loss: 0.2297 - accuracy: 0.9091 - val_loss: 0.3251 - val_accuracy: 0.9103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tuj2QA8YGqn"
      },
      "source": [
        "# Restore the model and construct the encoder and decoder.\n",
        "model_temp = model \n",
        "model = keras.models.load_model(\"third.h5\")\n",
        "\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim_encoder,)) #input 3\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim_encoder,)) # input 4\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "# reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "# reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, encoder_vocab.num_words))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, encoder_vocab.word2index['SOS']] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = [\"SOS\"]\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = encoder_vocab.index2word[sampled_token_index]\n",
        "        decoded_sentence.append(sampled_char)\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"EOS\" or len(decoded_sentence) > decoder_vocab.longest_sentence:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1,  encoder_vocab.num_words))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izecdG3ZB2xQ"
      },
      "source": [
        "def de_normalise(toks,index,data):\n",
        "  #Removing SOS ,EOS , OOV \n",
        "  c=s=com=n=0\n",
        "  toks = [i for i in toks if i not in ('SOS','EOS','PAD')]\n",
        "  \n",
        "  for i,x in enumerate(toks):\n",
        "    if (x[0]=='v' and x[1:].isdigit()):\n",
        "        id= int(x[1:])\n",
        "        if len(data['src_id_var'][index]) > 0:\n",
        "          toks[i] = data['src_id_var'][index][id%(len(data['src_id_var'][index]))]\n",
        "        continue\n",
        "    if x == 'lc_s' and s < len(data['src_lc_s'][index]) :\n",
        "      toks[i]=data['src_lc_s'][index][s]\n",
        "      s+=1\n",
        "      continue\n",
        "    if x == 'lc_c' and c < len(data['src_lc_c'][index]):\n",
        "      toks[i]=data['src_lc_c'][index][c]\n",
        "      c+=1\n",
        "      continue\n",
        "    if x == 'lc_n' and n < len(data['src_lc_n'][index]):\n",
        "      toks[i]=data['src_lc_n'][index][n]\n",
        "      n+=1\n",
        "      continue\n",
        "    if x == 'lc_com' and com < len(data['src_lc_com'][index]):\n",
        "      toks[i]=data['src_lc_com'][index][com]\n",
        "      com+=1\n",
        "      continue\n",
        "    \n",
        "  return toks\n",
        "      \n",
        "\n",
        "\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmiuRdEgEbpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5031dfec-79ba-4570-f0fa-ca696fac6e06"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "dist={}\n",
        "\n",
        "train_orig = pd.read_csv('/content/drive/MyDrive/ASEML_dataset/train.csv')\n",
        "test_orig = pd.read_csv('/content/drive/MyDrive/ASEML_dataset/valid.csv')\n",
        "tokenizer = tokenization.C_Tokenizer()\n",
        "for index in train_orig.index:\n",
        "  tar_line = ast.literal_eval(train_orig['targetLineTokens'][index])\n",
        "  line = ' '.join(tar_line)\n",
        "  toks,types = tokenizer.tokenize(line)\n",
        "  train_orig['targetLineTokens'][index] = toks\n",
        "for index in test_orig.index: \n",
        "  tar_line = ast.literal_eval(test_orig['targetLineTokens'][index])\n",
        "  line = ' '.join(tar_line)\n",
        "  toks,types = tokenizer.tokenize(line)\n",
        "  test_orig['targetLineTokens'][index] = toks\n",
        "  "
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A25AR8Dnkxx",
        "outputId": "7df9be94-681d-4a6e-b6ed-e48b7c457941"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           [(None, None, 422)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_28 (InputLayer)           [(None, None, 422)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_20 (LSTM)                  [(None, 160), (None, 373120      input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_21 (LSTM)                  [(None, None, 160),  373120      input_28[0][0]                   \n",
            "                                                                 lstm_20[0][1]                    \n",
            "                                                                 lstm_20[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, None, 422)    67942       lstm_21[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 814,182\n",
            "Trainable params: 814,182\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a6GOktiLQ2E"
      },
      "source": [
        "# Encoder input for test data\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(test),encoder_vocab.longest_sentence, encoder_vocab.num_words), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(test), encoder_vocab.longest_sentence, encoder_vocab.num_words), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(test), encoder_vocab.longest_sentence, encoder_vocab.num_words), dtype=\"float32\"\n",
        ")\n",
        "for i, (input_text, target_text) in enumerate(zip(test['sourceLineTokens'],test['targetLineTokens'])):\n",
        "    for t, char in enumerate(input_text):\n",
        "      if char in encoder_vocab.word2index:\n",
        "        encoder_input_data[i, t, encoder_vocab.word2index[char]] = 1.0\n",
        "      else:\n",
        "        encoder_input_data[i, t, encoder_vocab.word2index['OOV_Token']] = 1.0\n",
        "    \n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        if char in encoder_vocab.word2index:\n",
        "          decoder_input_data[i, t, encoder_vocab.word2index[char]] = 1.0\n",
        "        else:\n",
        "          decoder_input_data[i, t, encoder_vocab.word2index['OOV_Token']] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            if char in encoder_vocab.word2index:\n",
        "              decoder_target_data[i, t-1, encoder_vocab.word2index[char]] = 1.0\n",
        "            else:\n",
        "              decoder_target_data[i, t-1, encoder_vocab.word2index['OOV_Token']] = 1.0"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfm9byYnfDJu",
        "outputId": "1201ff82-d4bb-4b39-d036-4a61028e80c5"
      },
      "source": [
        "# Predicting sequeneces \n",
        "correct = 0\n",
        "samples = 10\n",
        "test_orig['fixedTokens'] = \"\"\n",
        "for index in range(samples):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[index : index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    decoded_sentence = de_normalise(decoded_sentence,index,test)\n",
        "    test_orig['fixedTokens'][index]=decoded_sentence\n",
        "    if decoded_sentence == test_orig['targetLineTokens'][index]:\n",
        "      correct+=1\n",
        "    if index % 100 == 0 and index != 0: \n",
        "      print('accuracy: after',index,': ',correct/index)\n",
        "\n",
        "print('Accuracy : ',correct/samples)\n",
        "    "
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0UHDft4DE8g"
      },
      "source": [
        "# load and store dictionaires \n",
        "import pickle\n",
        "file_to_store = open(\"en_vocab.pickle\", \"wb\")\n",
        "pickle.dump(encoder_vocab, file_to_store)\n",
        "file_to_store.close()\n",
        "\n",
        "file_to_store = open(\"dec_vocab.pickle\", \"wb\")\n",
        "pickle.dump(decoder_vocab, file_to_store)\n",
        "file_to_store.close()"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV-oGBhID--e",
        "outputId": "0fc8a87e-e8b2-46e6-c8ea-54ad7b7ee459"
      },
      "source": [
        "file_to_read = open(\"vocab.pickle\", \"rb\")\n"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crUsM8MbIxRi",
        "outputId": "15875830-8d41-4ba0-bf95-325fc7af27ce"
      },
      "source": [
        "a=pd.read_csv('valid_output.csv')\n",
        "print(ast.literal_eval(a['fixedTokens'][0]))\n",
        "print(a['targetLineTokens'][0])"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['if', '(', '(', 'x', '(', 'facdtorial', ')', '&&', '(', 'x', '>=', 'n2', ')', ')', '&&', '(', 'facdtorial', '<', 'x']\n",
            "['if', '(', '(', 'factorial', '(', 'x', ')', '>=', 'n1', ')', '&&', '(', 'factorial', '(', 'x', ')', '<=', 'n2', ')', ')', '{']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}